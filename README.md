# ğŸ™ï¸ **AI Video Communication Analyzer**

*A local end-to-end pipeline for downloading audio, transcribing it with Whisper, and generating clarity, focus, and summary insights.*

## â­ **Overview**

https://github.com/user-attachments/assets/63c42cd3-0e93-46f5-afc1-ba6e42e43f1d



This project analyzes communication quality from any **YouTube video URL** or **local audio/video file**.

It performs:

1. **Audio Extraction**
2. **Transcription (Faster-Whisper â€” fully local, offline)**
3. **Communication Analysis:**

   * Clarity Score
   * One-sentence Focus
   * Short Summary

This tool is ideal for analyzing motivational talks, presentations, interviews, or speeches.

## ğŸš€ **Features**

* ğŸ¥ Accepts **YouTube URLs** or **local audio/video paths**
* ğŸ§ Automatically downloads **best audio format**
* ğŸ“ Local transcription using **Whisper (large-v3-turbo)**
* ğŸ“Š Natural language analysis without any API
* ğŸ” Debug panel for raw outputs
* âš¡ Minimal, stable, and deployment-friendly codebase


## ğŸ—‚ï¸ **Project Structure**


ai-video-communication-analyzer/
â”‚
â”œâ”€â”€ app.py                     # Streamlit main application
â”œâ”€â”€ requirements.txt           # Dependencies
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ download.py            # Clean yt-dlp audio downloader
    â”œâ”€â”€ transcribe_local.py    # Faster-Whisper transcription
    â””â”€â”€ analysis_local_llm.py  # Clarity, focus, summary analysis
```


## ğŸ’» **Local Setup Guide (Windows)**

### 1ï¸âƒ£ **Clone the Repo**


git clone https://github.com/Likhithgowdak6/Ai-video-communication-analyzer
cd ai-video-communication-analyzer
```

### 2ï¸âƒ£ **Create & Activate Virtual Environment**

```
python -m venv env
env\Scripts\activate
```

### 3ï¸âƒ£ **Install Dependencies**

```
pip install -r requirements.txt
```

### 4ï¸âƒ£ **Install system dependencies**

Whisper needs FFmpeg.
Download FFmpeg for Windows:
[https://www.gyan.dev/ffmpeg/builds/](https://www.gyan.dev/ffmpeg/builds/)

Extract â†’ Copy `ffmpeg.exe` into PATH or inside project folder.

### 5ï¸âƒ£ **Run the App**

```
streamlit run app.py
```
## ğŸ§  **How the Pipeline Works**

### **Step 1: Input Detection**

User enters:

* a YouTube URL
* OR a local file path (MP4, M4A, WAV, etc.)

If the file exists â†’ skip download
Else â†’ treat it as URL.

---

### **Step 2: Audio Extraction**

Handled by `utils/download.py`:

* Uses **yt-dlp**
* Downloads **bestaudio** format
* Ignores JS runtime issues
* Returns file like:

  ```
  audio_input_1763832456.m4a
  ```

If download fails â†’ returns clean error message.

---

### **Step 3: Transcription**

`utils/transcribe_local.py`:

* Loads **faster-whisper (large-v3-turbo)**
* Runs **local transcription**
* Outputs `transcript.txt`

---

### **Step 4: Text Analysis**

`utils/analysis_local_llm.py` performs:

* Word tokenizing
* Sentence segmentation
* Repetition compression
* Filler count
* Extracts focus sentence
* Generates 2â€“3 line summary
* Produces clarity score (0â€“100)

No external LLM or API required.

---

### **Step 5: UI Output**

* Clarity Score meter
* Communication Focus (1 line)
* Short Summary
* Expandable debug info

---

## ğŸ§© **File Management**

The app auto-manages:

```
transcript.txt                  # Latest transcript
audio_input_<timestamp>.*       # Auto-generated audio files
```

On every run:

* Old audio files are ignored
* Old transcript is removed
* New timestamped audio is used

---

## ğŸ“¦ **requirements.txt**

```
streamlit
yt-dlp
faster-whisper==1.0.3
numpy
python-dotenv
requests
tqdm
soundfile
ffmpeg-python
```

## âš ï¸ **Common Issues**

### âŒ yt-dlp failed to download audio

âœ” Try using a different YouTube URL
âœ” Try running locally (Streamlit Cloud may block downloads)

### âŒ faster-whisper model too large

Large models may take time to loadâ€”first run is slow.

### âŒ FFmpeg not found

Install ffmpeg manually and add to PATH.

---

## ğŸŒ **Deployment Notes**

### Streamlit Cloud

âŒ Not supported â€” cannot install system-level libraries required for Whisper (`av`, `pkg-config`, FFmpeg).

### Flask Deployment

âœ” Works on any cloud VM with FFmpeg + Python
âŒ Requires access to AWS / Render / Railway / GCP to install system dependencies.

If needed, future-ready deployment scripts can be added.

---

## ğŸ **Conclusion**

This project delivers a fully functional **local AI communication analysis pipeline**, with:

* Clear modular structure
* Minimal dependencies
* Local LLM-free analysis
* Whisper transcription
* Clean Streamlit UI
